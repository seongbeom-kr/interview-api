{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "979c1867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26a25025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "portfolio-interview-qa\n",
      "면접 질문이 interview_questions.txt 파일에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "logging.langsmith(\"portfolio-interview-qa\")\n",
    "\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. PDF 로딩 및 분할\n",
    "loader = PyMuPDFLoader(\"data.pdf\")\n",
    "docs = loader.load()\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "chunks = splitter.split_documents(docs)\n",
    "\n",
    "# 2. 프로젝트/기술스택 요약\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "summary_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an expert IT recruiter. Summarize the main projects and technical stacks from the following portfolio text. Respond in bullet points. Only return the summary, no explanations.\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "summary_chain = summary_prompt | llm | StrOutputParser()\n",
    "summaries = [summary_chain.invoke({\"input\": chunk.page_content}) for chunk in chunks]\n",
    "full_summary = \"\\n\".join(summaries)\n",
    "\n",
    "# 3. 고퀄리티 질문 생성 (문제 해결 질문 포함, 한국어)\n",
    "question_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are a senior software engineer and technical interviewer. \"\n",
    "     \"Based on the following portfolio summary, generate exactly 5 high-quality, in-depth interview questions in Korean. \"\n",
    "     \"3 questions must be based on the candidate's projects/experience, and 2 questions must be based on their technical stack. \"\n",
    "     \"Among the project-based questions, at least one must ask in detail about a specific problem or challenge the candidate faced during a project and how they solved or overcame it. \"\n",
    "     \"Questions should require deep reasoning, real-world application, and critical thinking. \"\n",
    "     \"Be creative and avoid generic questions. \"\n",
    "     \"Label each question as [Portfolio] or [Tech Stack]. \"\n",
    "     \"Return only the questions as a numbered list. \"\n",
    "     \"All questions must be written in Korean.\"),\n",
    "    (\"human\", \"{summary}\")\n",
    "])\n",
    "question_chain = question_prompt | llm | StrOutputParser()\n",
    "questions = question_chain.invoke({\"summary\": full_summary})\n",
    "\n",
    "# 4. 질문을 txt 파일로 저장\n",
    "with open(\"interview_questions.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(questions)\n",
    "\n",
    "print(\"면접 질문이 interview_questions.txt 파일에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "117337b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "상세 피드백이 interview_feedback.txt 파일에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "\n",
    "# Q&A txt 파일 읽기\n",
    "with open(\"interview_qa.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    qa_text = f.read()\n",
    "\n",
    "criteria_feedback = \"\"\"\n",
    "아래의 각 평가 항목별로 지원자의 답변에 대해 매우 엄격하고 구체적으로 피드백을 작성하세요. 점수는 절대 포함하지 마세요.  \n",
    "각 항목별로 한 문단 이상의 상세 피드백을 작성하세요.\n",
    "\n",
    "[기술 질문 평가 항목]\n",
    "- 핵심 기술 개념의 이해도\n",
    "- 비교 및 분석 능력\n",
    "- 성능 최적화 고려\n",
    "- 최신 트렌드 반영\n",
    "- 기술 용어의 정확성과 일관성\n",
    "\n",
    "[포트폴리오 질문 평가 항목]\n",
    "- 프로젝트 기반 설명력\n",
    "- 문제 해결 과정의 명확성\n",
    "- 결과 도출 및 개선 노력\n",
    "- 실무 적용 가능성\n",
    "- 협업 및 기여도 표현\n",
    "\n",
    "피드백은 반드시 한국어로 작성하세요.\n",
    "\"\"\"\n",
    "\n",
    "feedback_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", f\"당신은 시니어 소프트웨어 엔지니어이자 기술 면접관입니다. 아래의 평가 기준에 따라 지원자의 답변을 평가하세요.\\n{criteria_feedback}\\n\"),\n",
    "    (\"human\", \"{qa_text}\")\n",
    "])\n",
    "feedback_chain = feedback_prompt | llm | StrOutputParser()\n",
    "feedback_only = feedback_chain.invoke({\"qa_text\": qa_text})\n",
    "\n",
    "with open(\"interview_feedback.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(feedback_only)\n",
    "print(\"상세 피드백이 interview_feedback.txt 파일에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03f02ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "점수만 interview_scores.txt 파일에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 피드백 파일 읽기\n",
    "with open(\"interview_feedback.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    feedback_text = f.read()\n",
    "\n",
    "criteria_score = \"\"\"\n",
    "아래의 각 평가 항목별로 0~100점 만점으로 매우 엄격하게 점수를 매기세요.\n",
    "아래 형식만 출력하세요(불필요한 설명, 번호, 공백 없이):\n",
    "\n",
    "핵심 기술 개념의 이해도: X/100\n",
    "비교 및 분석 능력: X/100\n",
    "성능 최적화 고려: X/100\n",
    "최신 트렌드 반영: X/100\n",
    "기술 용어의 정확성과 일관성: X/100\n",
    "프로젝트 기반 설명력: X/100\n",
    "문제 해결 과정의 명확성: X/100\n",
    "결과 도출 및 개선 노력: X/100\n",
    "실무 적용 가능성: X/100\n",
    "협업 및 기여도 표현: X/100\n",
    "\n",
    "반드시 위 10개 항목만, '항목명: X/100' 형식으로 한 줄씩 출력하세요.  \n",
    "점수만 출력하고, 다른 설명은 절대 포함하지 마세요.\n",
    "\"\"\"\n",
    "\n",
    "score_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", f\"당신은 시니어 소프트웨어 엔지니어이자 기술 면접관입니다. 아래의 피드백을 읽고 각 항목별 점수를 산출하세요.\\n{criteria_score}\\n\"),\n",
    "    (\"human\", \"{feedback_text}\")\n",
    "])\n",
    "score_chain = score_prompt | llm | StrOutputParser()\n",
    "scores_only = score_chain.invoke({\"feedback_text\": feedback_text})\n",
    "\n",
    "with open(\"interview_scores.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(scores_only)\n",
    "print(\"점수만 interview_scores.txt 파일에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bd6583",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
