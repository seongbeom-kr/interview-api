1. YOLOv8 실시간 객체 탐지에서 백본(VGG, ResNet) 실험과 성능 평가

답변:
YOLOv8 구조에서 백본 교체 실험은 주로 모델의 추론 속도와 정확도 간의 트레이드오프를 평가하기 위해 수행했습니다.
VGG는 구조가 단순해서 연산량이 많고 파라미터 수가 많지만, 학습 안정성은 높았습니다. 반면 ResNet은 잔차 연결을 통해 더 깊은 구조에서도 성능 저하 없이 학습이 가능하고, 파라미터 효율이 더 좋았습니다.

실시간 성능 측정은 FPS(초당 프레임 수), mAP(mean Average Precision), 모델 사이즈, latency 등을 기준으로 했습니다.
VGG 백본은 정확도는 괜찮았지만 추론 속도가 느려서 실시간 애플리케이션에는 부적합했습니다.
ResNet-18, 34 정도가 속도와 정확도 간 균형이 잘 맞아 실제 적용에는 더 적합했습니다.

최적화는 ONNX 변환, TensorRT, 그리고 이미지 해상도 조절을 통해 수행했으며, 최종적으로 ResNet-34 기반 모델이 가장 우수한 결과를 보였습니다.

⸻

2. RAG 기반 배터리 데이터셋 구축과 FAISS + LangGraph로 검색 강화

답변:
배터리 분야는 공개 데이터가 제한적이어서, 초기에는 학술 논문 PDF와 보고서를 크롤링하여 데이터를 수집했습니다.
이후 LangChain 기반 문서 청크화 및 텍스트 전처리를 통해 반정형 데이터셋을 구성했습니다.

데이터 부족 문제는 오픈 도메인 학습 기반의 보강과 함께 **유사 문서 생성(Augmentation)**을 통해 보완했습니다. 예를 들어, 기존 문서의 내용을 요약하거나 확장하는 방식으로 RAG의 context input을 확장했습니다.

검색 성능 강화를 위해 FAISS를 사용하여 벡터 검색을 구성했는데, cosine similarity 기준으로 Top-k 문서를 빠르게 추출할 수 있도록 하였고,
LangGraph를 활용하여 검색 → 관련성 평가 → LLM 답변 생성 흐름을 그래프 기반으로 명확히 분리했습니다.
이런 구성 덕분에 irrelevant 문서가 포함되는 비율이 줄어들고, RAG의 응답 품질이 향상되었습니다.

⸻

3. SHAP vs LIME: 차이점, 장단점, 실제 활용 사례

답변:
SHAP과 LIME은 모두 모델 예측에 대한 feature 중요도를 시각화하는 XAI 기법이지만 접근 방식이 다릅니다.

	•	LIME은 국소적인 선형 모델을 만들어 예측을 설명하며, 계산이 빠르고 직관적입니다. 하지만 노이즈에 민감하고 일관성이 부족할 수 있습니다.
	•	SHAP은 게임 이론 기반의 shapley 값을 이용해 전역적 일관성과 feature 상호작용을 더 정확히 설명할 수 있지만, 계산량이 많고 느립니다.

실제 프로젝트에서는 고객 이탈 예측 모델에 대해 두 방법을 모두 적용해봤습니다.
초기 분석에는 LIME을 사용해 빠르게 인사이트를 도출하고, 모델 릴리스 전에는 SHAP을 활용해 보다 정교한 feature 영향도를 시각화했습니다.

예를 들어, SHAP을 통해 ‘가입 기간’이 장기 고객일수록 이탈 확률에 미치는 영향이 반전되는 현상을 발견했고, 이를 바탕으로 segment 별 정책을 차별화하는 전략을 제시했습니다.

⸻

4. PyTorch vs TensorFlow: 구조와 성능 최적화 고려사항

답변:
PyTorch는 동적 그래프 기반으로 직관적이고 디버깅이 쉬워 빠른 프로토타이핑에 적합합니다. 반면 TensorFlow는 정적 그래프 기반으로 생산 단계에서의 최적화와 배포에 강점이 있습니다.

성능 최적화 관점에서는 다음과 같은 고려사항이 있습니다:
	•	PyTorch: torchscript, ONNX, torch.compile()을 활용한 그래프 최적화, AMP(자동 혼합 정밀도), DDP(분산 학습)로 속도 개선 가능
	•	TensorFlow: XLA 컴파일러, tf.data 파이프라인 최적화, SavedModel 포맷 및 TensorRT를 통한 배포 최적화가 주요 포인트입니다.

개발과 실험에는 PyTorch를 주로 사용하지만, 배포 환경이 제한적일 경우 TensorFlow를 선택한 경험도 있습니다.

⸻

5. ViT vs CNN: 이미지 분류에서의 비교와 학습 안정화 기법

답변:
ViT는 이미지 패치를 입력으로 받아 self-attention을 통해 long-range dependency를 학습할 수 있다는 점에서 CNN과 차별화됩니다.
이 덕분에 데이터가 충분하다면 복잡한 구조나 전역 패턴을 잘 포착할 수 있습니다. 하지만 CNN보다 학습에 훨씬 많은 데이터와 정교한 사전 학습이 필요합니다.

단점은 학습 불안정성과 데이터 효율성 낮음인데, 이를 해결하기 위해 다음 기법을 사용했습니다:
	•	LayerScale: Transformer의 각 layer에 작은 스케일 계수를 곱해 그래디언트 폭주 완화
	•	Stochastic Depth: 일부 레이어를 확률적으로 생략하여 regularization
	•	Knowledge Distillation: CNN teacher로부터 ViT를 학습

실제 프로젝트에서는 ViT와 ResNet-50을 비교했을 때, ViT가 세부적인 패턴 구분에는 뛰어났지만, 학습 속도나 소규모 데이터셋에서는 ResNet이 더 안정적이었습니다. 그래서 두 모델을 앙상블하는 방식으로 성능을 개선했습니다.